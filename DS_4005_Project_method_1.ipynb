{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cuNS3keDVGB"
      },
      "outputs": [],
      "source": [
        "# Minimal DR Triple Cross-Fit\n",
        "# Based on Ke et al. (2023)\n",
        "\n",
        "!pip install opendatasets xgboost\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import opendatasets as od\n",
        "import os, re, cv2, gc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 1. DATA LOADING\n",
        "od.download(\"https://www.kaggle.com/datasets/khanfashee/nih-chest-x-ray-14-224x224-resized/data\")\n",
        "\n",
        "CSV_PATH = '/content/nih-chest-x-ray-14-224x224-resized/Data_Entry_2017.csv'\n",
        "IMG_DIR = '/content/nih-chest-x-ray-14-224x224-resized/images-224/images-224'\n",
        "TARGET_N = 3500       # target sample size\n",
        "IMG_SIZE = (224,224)\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Metadata preprocessing\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df['Finding Labels'] = df['Finding Labels'].astype(str).str.strip()\n",
        "\n",
        "def list_all_labels(series):\n",
        "    labels = set()\n",
        "    for row in series:\n",
        "        for lab in row.split('|'):\n",
        "            labels.add(lab.strip())\n",
        "    return sorted(labels)\n",
        "\n",
        "def has_label(s, lab):\n",
        "    lab_esc = re.escape(lab)\n",
        "    return bool(re.search(rf'(^|\\|){lab_esc}($|\\|)', s))\n",
        "\n",
        "all_labels = list_all_labels(df['Finding Labels'])\n",
        "for lab in all_labels:\n",
        "    df[lab] = df['Finding Labels'].apply(lambda s: 1 if has_label(s, lab) else 0)\n",
        "\n",
        "df['Age_clean'] = df['Patient Age'].astype(str).str.extract(r'(\\d+)').astype(float)\n",
        "df['image_path'] = df['Image Index'].apply(lambda f: os.path.join(IMG_DIR, f))\n",
        "df = df[df['image_path'].apply(os.path.exists)].reset_index(drop=True)\n",
        "\n",
        "\n",
        "# NEW SAMPLING: All pneumonia cases + random non-pneumonia until 3500\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# All pneumonia-positive cases\n",
        "pneu_pos = df[df['Pneumonia'] == 1]\n",
        "\n",
        "# All non-pneumonia cases\n",
        "pneu_neg = df[df['Pneumonia'] == 0]\n",
        "\n",
        "# How many negatives needed to reach target\n",
        "needed_neg = max(0, TARGET_N - len(pneu_pos))\n",
        "\n",
        "# Randomly sample negatives\n",
        "pneu_neg_sample = pneu_neg.sample(n=needed_neg, random_state=RANDOM_SEED)\n",
        "\n",
        "# Combine positives + sampled negatives\n",
        "sample_df = pd.concat([pneu_pos, pneu_neg_sample], axis=0)\n",
        "\n",
        "# Shuffle dataset\n",
        "sample_df = sample_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "\n",
        "print(\"Final sample size:\", len(sample_df))\n",
        "print(\"Pneumonia cases:\", sample_df['Pneumonia'].sum())\n",
        "print(\"Non-Pneumonia cases:\", len(sample_df) - sample_df['Pneumonia'].sum())\n",
        "\n",
        "\n",
        "# Covariates (Z), Treatment (T), Outcome (Y)\n",
        "covar_disease_cols = [c for c in all_labels if c not in ['Pneumonia','Infiltration','No Finding']]\n",
        "gender_map = {'M': 1, 'F': 0}\n",
        "sample_df['Gender_enc'] = sample_df['Patient Gender'].map(gender_map)\n",
        "view_dummies = pd.get_dummies(sample_df['View Position'], prefix=\"ViewPos\")\n",
        "\n",
        "Z = np.column_stack([\n",
        "    sample_df['Age_clean'].to_numpy().astype(float),\n",
        "    sample_df['Gender_enc'].to_numpy().astype(int),\n",
        "    sample_df[covar_disease_cols].to_numpy().astype(int),\n",
        "    view_dummies.to_numpy().astype(int)\n",
        "])\n",
        "Y = sample_df['Pneumonia'].to_numpy().astype(int)\n",
        "T = sample_df['Infiltration'].to_numpy().astype(int)\n",
        "\n",
        "print(\"Z:\", Z.shape, \"Y:\", Y.shape, \"T:\", T.shape)\n",
        "\n",
        "\n",
        "\n",
        "# 2. IMAGE PREPROCESSING\n",
        "def preprocess_image_rgb(path, size=IMG_SIZE, dtype=np.float32):\n",
        "    img = cv2.imread(path)\n",
        "    if img is None: return None\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, size)\n",
        "    return (img.astype(dtype) / 255.0)\n",
        "\n",
        "X_list, drop_idx = [], []\n",
        "for i, p in enumerate(sample_df['image_path'].tolist()):\n",
        "    arr = preprocess_image_rgb(p)\n",
        "    if arr is None: drop_idx.append(i)\n",
        "    else: X_list.append(arr)\n",
        "\n",
        "if drop_idx:\n",
        "    keep = np.ones(len(sample_df), dtype=bool)\n",
        "    keep[drop_idx] = False\n",
        "    sample_df = sample_df[keep].reset_index(drop=True)\n",
        "    Z, Y, T = Z[keep], Y[keep], T[keep]\n",
        "\n",
        "X = np.stack(X_list, axis=0).astype(np.float32)\n",
        "del X_list; gc.collect()\n",
        "\n",
        "print(\"X:\", X.shape, \"Z:\", Z.shape, \"T:\", T.shape, \"Y:\", Y.shape)\n",
        "\n",
        "\n",
        "# 3. HDFPCA\n",
        "def perform_hdfpca(X, variance_threshold=0.95):\n",
        "    n = X.shape[0]\n",
        "    mean_image = np.mean(X, axis=0)\n",
        "    X_centered = X - mean_image\n",
        "    X_mat = X_centered.reshape(n, -1)\n",
        "    U, s, Vt = np.linalg.svd(X_mat.T, full_matrices=False)\n",
        "    eigenvalues = s**2 / (n - 1)\n",
        "    cumulative_var = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
        "    n_components = np.argmax(cumulative_var >= variance_threshold) + 1\n",
        "    U_selected = U[:, :n_components]\n",
        "    s_selected = s[:n_components]\n",
        "    eigenscores = (np.diag(s_selected) @ Vt[:n_components, :]).T\n",
        "    return eigenscores, U_selected, s_selected, mean_image\n",
        "\n",
        "def transform_with_hdfpca(X, U, s, mean_image):\n",
        "    n = X.shape[0]\n",
        "    X_centered = X - mean_image\n",
        "    X_mat = X_centered.reshape(n, -1)\n",
        "    return X_mat @ U\n",
        "\n",
        "\n",
        "# 4. DR TRIPLE CROSS-FIT (Logistic Regression only)\n",
        "def dr_score(y, t, ps, m1, m0):\n",
        "    ps = np.clip(ps, 1e-6, 1-1e-6)\n",
        "    return (m1 - m0) + (t * (y - m1) / ps) - ((1 - t) * (y - m0) / (1 - ps))\n",
        "\n",
        "def triple_crossfit_dr_simple(X_imgs, Z, T, Y, cpv=0.95, P=3, random_state=42):\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    n = len(Y)\n",
        "    ate_list = []\n",
        "\n",
        "    for p in range(P):\n",
        "        idx = np.arange(n)\n",
        "        rng.shuffle(idx)\n",
        "        folds = np.array_split(idx, 4)\n",
        "        rot_ates = []\n",
        "\n",
        "        for r in range(4):\n",
        "            A,B,C,D = folds[r], folds[(r+1)%4], folds[(r+2)%4], folds[(r+3)%4]\n",
        "\n",
        "            # HDFPCA on fold A\n",
        "            try:\n",
        "                eig_A,U_A,s_A,mean_A = perform_hdfpca(X_imgs[A], variance_threshold=cpv)\n",
        "            except: continue\n",
        "\n",
        "            # Transform folds\n",
        "            ES_B = transform_with_hdfpca(X_imgs[B], U_A, s_A, mean_A)\n",
        "            ES_C = transform_with_hdfpca(X_imgs[C], U_A, s_A, mean_A)\n",
        "            ES_D = transform_with_hdfpca(X_imgs[D], U_A, s_A, mean_A)\n",
        "\n",
        "            XB = np.column_stack([Z[B], ES_B])\n",
        "            XC = np.column_stack([Z[C], ES_C])\n",
        "            XD = np.column_stack([Z[D], ES_D])\n",
        "\n",
        "            scaler = StandardScaler().fit(np.vstack([XB,XC]))\n",
        "            XB,XC,XD = scaler.transform(XB),scaler.transform(XC),scaler.transform(XD)\n",
        "\n",
        "            # Propensity model on B\n",
        "            try:\n",
        "                prop_model = LogisticRegression(max_iter=1000).fit(XB, T[B])\n",
        "            except: continue\n",
        "\n",
        "            #  Outcome models on C\n",
        "            XC_t1,Y_t1 = XC[T[C]==1], Y[C][T[C]==1]\n",
        "            XC_t0,Y_t0 = XC[T[C]==0], Y[C][T[C]==0]\n",
        "            if len(XC_t1)==0 or len(XC_t0)==0: continue\n",
        "\n",
        "            try:\n",
        "                out1_model = LogisticRegression(max_iter=1000).fit(XC_t1, Y_t1)\n",
        "                out0_model = LogisticRegression(max_iter=1000).fit(XC_t0, Y_t0)\n",
        "            except: continue\n",
        "\n",
        "            # Predict on D\n",
        "            try:\n",
        "                ps_D = prop_model.predict_proba(XD)[:,1]\n",
        "                m1_D = out1_model.predict_proba(XD)[:,1]\n",
        "                m0_D = out0_model.predict_proba(XD)[:,1]\n",
        "            except: continue\n",
        "\n",
        "            phi = dr_score(Y[D], T[D], ps_D, m1_D, m0_D)\n",
        "            rot_ates.append(phi.mean())\n",
        "\n",
        "        if rot_ates:\n",
        "            ate_list.append(np.mean(rot_ates))\n",
        "\n",
        "    if not ate_list:\n",
        "        return {\"ATE\": np.nan,\"SE\":np.nan,\"CI\":(np.nan,np.nan),\"P_used\":0}\n",
        "\n",
        "    ate_hat = np.median(ate_list)\n",
        "    se_hat = np.std(ate_list)/np.sqrt(len(ate_list))\n",
        "    ci_low, ci_high = ate_hat - 1.96*se_hat, ate_hat + 1.96*se_hat\n",
        "\n",
        "    return {\"ATE\": ate_hat,\"SE\":se_hat,\"CI\":(ci_low,ci_high),\"P_used\":len(ate_list)}\n",
        "\n",
        "\n",
        "# 5. RUN\n",
        "print(\"Running DR Triple Cross-Fit (LogReg only)...\")\n",
        "result = triple_crossfit_dr_simple(X, Z, T, Y, cpv=0.95, P=3, random_state=42)\n",
        "\n",
        "print(\"\\n===== RESULTS =====\")\n",
        "print(f\"ATE: {result['ATE']:.4f}\")\n",
        "print(f\"SE : {result['SE']:.4f}\")\n",
        "print(f\"95% CI: [{result['CI'][0]:.4f}, {result['CI'][1]:.4f}]\")\n",
        "print(f\"Partitions used: {result['P_used']}\")"
      ]
    }
  ]
}